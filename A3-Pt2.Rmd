---
title: "TITLE OF YOUR PROJECT"
author: "Group 4"
date: "November 12th, 2024"
output: pdf_document
---

List your group members, including their student numbers, here:

- Harsahib Grewal (169089650)
- David Zhao (#########)
- Chee Kian Teoh (#########)
- Dumebi Nasa Okolie (########)
- N/A (N/A)

You **must** be in a group in MyLS in order to see the DropBox used for submission. Even if you're alone, you must join a group by yourself.

You **must** be in a group with people from the same section as you. MyLS does not allow for groups including students from both Data100A and Data100B.

```{r setup, include=FALSE}
# echo = FALSE will set the Rmd to *not* show the R code. Don't change this.
# You may change the default figure width and figure height as you please.
knitr::opts_chunk$set(echo = FALSE, message = FALSE, fig.width = 6)

# Put any libraries that you need to load here.
# DO NOT PUT "install.packages()" IN AN RMD FILE!!!
library(tidyverse)
library(arrow)
```


# Instructions

You will only submit the PDF version of this document. To knit to PDF, you'll need to run `install.packages("tinytex")` in the console, followed by `tinytex::install_tinytex()` (DO NOT PUT THESE COMMANDS IN AN RMD FILE!!!). If you encounter errors in "Knit to PDF", you can "knit to html" and then print the html file to PDF using your operating system's PDF view (e.g. Adobe Acrobat). Only standalone PDF files will be accepted by MyLS.

# Abstract

General context, very brief data descriptions, techniques used, and general conclusions, all contained within a single, concise paragraph.

# Introduction

Climate change is a topic of extensive study and recently more challenges have arisen for environmental and public health, economic stability, and global ecosystems. As the climate continues to change because of natural events and human activities, the consequences are becoming more and more visible. The analysis looks at some of these impacts by getting data on natural events and public health and connecting them to see any emerging patterns that can lead to the answer of if they have any relation to the environmental change over recent decades.

In this report, some key indicators of climate change versus global response factors are explored through exploratory analysis. The datasets we use look at the strength, and frequency of hurricanes in the Atlantic and North Pacific basins; polar ice extent in the Arctic and Antarctic regions; and COVID-19 reported cases around the world during the year 2020. Some techniques used in this analysis are data visualization and statistical explorations of any trends and possible correlations (whether high or low) within the data.

The goal of this analysis is to learn patterns in these datasets and see the finer relation among these factors that may provide insight into what is affecting climate change. There are several limitations to the data here mainly around time and geographical locations, but this report still tries to show the relationships of climate events and their outcomes. 

By the end of this report, we will explain these correlations and provide a conclusion supported with evidence of the current impact of climate change.

# Data Description

## <<Data Set 1>>

```{r load_data1}
# Put in your code to load in the data set, along with any
# necessary cleaning beyond what was done in Part 1

# Note that the code in this document will not be shown
# when you click "knit", so the placement of this code
# chunk is purely for your benefit: You can see what happened
# with your data, which makes it easier to describe below!
```

The data comes from <<place>> and describe <<more specific description of the data>>.

The cyclones dataset shows data on hurricane activity across the Atlantic and North Pacific basins. Some important columns include cyclone strength (maximum wind speed, and category), cyclone duration, and basin of origin. More columns had similar attributes which were grouped such as geographical coordinates (latitude and longitude) of the cyclones at recorded times and dates of occurrence. This dataset allows us to analyze hurricane frequency, strength, and duration trends across different regions.

In order to clean the data, we:
- Remove any records with missing values in key columns such as wind speed and pressure to ensure accuracy in cyclone strength measurements.
- Standardize date and time formats and convert them to datetime types where applicable.
- Remove any duplicate records based on unique cyclone identifiers and timestamps.


## <<Data Set 2>>

```{r load_data2}
# Put in your code to load in the data set, along with any
# necessary cleaning beyond what was done in Part 1

# Reminder: do NOT print your data to the screen unless it's
# completely necessary
```

The data comes from <<place>> and detail <<more specific description of the data>>.

This dataset contains yearly data on ice extent in both the Arctic and Antarctic regions. Some important columns were year, region (Arctic or Antarctic), and ice extent measurements (km^2). This dataset shows polar ice coverage which is a significant cause of climate change, and this allows us to see the trend analysis over time to see potential reductions in ice extent.

In order to clean the data, we:
- Clean any missing values in the ice extent column to avoid gaps in yearly trend analysis.
- Convert the year column to datetime for consistency.
- Check for any duplicate records by year and region to maintain unique records.


## <<Data Set 3>>

```{r load_data2}
# Put in your code to load in the data set, along with any
# necessary cleaning beyond what was done in Part 1
```

The data comes from <<place>> and detail <<more specific description of the data>>.

The covid dataset reports total COVID-19 cases from 2020 to 2022 looking at most of the countries. Some important columns are the country name, total reported cases (new and old), deaths, population, and other demographic details relevant to the country's deaths to cases ratio. This dataset has a lot of empty data which wouldâ€™ve proven useful to find some relations (icu/hospital admissions and patients, COVID tests taken, and COVID vaccinations taken). Regardless of the missing material, this dataset allows us to explore the pandemic's global impact in 2020.

In order to clean the data, we:
- Remove all empty columns with missing data values
- Remove records with missing or zero values in the total cases and population columns.
- Standardize country names to ensure a common trend across the dataset.
- Convert any non-numeric data types in the reported cases and population columns to numeric for easier calculations.


## Combining the Data

Explain how any combinations of data were performed. Explain what kind of join was needed, whether columns had to be modified (for example, matching "country" names.)

For the combination of the ice_extent dataset and covid_2020 dataset we were interested in combining both tables by their date column so we can analyze and see the correlation between the melting ice and COVID-19 stringency (a measurement of how strict government policies were throughout the COVID-19 pandemic).

To achieve the combination we used "left_join" to combine the ice_extent dataset into the COVID_2020 dataset. The reasoning behind choosing to combine with a left_join is because the ice_extent dataset has a wider range of data collected going from 1980 to 2023 whereas covid_2020 only had data from 2020 to 2023. Because of this we wanted to show the data that overlapped while showing previous data from the ice_extent dataset to show if there is a correlation between the two and it not being the same as the years when the COVID pandemic did not exist.(hence why we don't use inner_join since it would only show the overlapping dates and not allow us to see if there really is a relation).



# Exploratory Data Analysis

To achieve our goals, we explored the data by...

We explored many aspects of the data, but will demonstrate three. These are <<insight 1>>, <<insight 2>>, and <<insight3>>

The first aspect that we found interesting is shown in \@ref(fig:insight1). The insight should be specific to the data shown, not a general statement beyond the data (leave that for the conclusion).

```{r insight1, fig.cap="This is a figure caption that you will need to change in order to get good marks in the visualization rubric items."}
# This is an example of how you can control figures and captions in
# an R chunk. Note that you can reference figures using:
# \@ref(fig:insight1), where "insight1" is the label of this code
# chunk (the first bit of text after the "r" in "```{r label, options...}")
```

This insight is supported by the summary statistics in table \@ref(tab:summary_stats)

```{r summary_stats}
# Calculate the relevant summary statistics here.
# Note that the "kable" function in the "knitr" package
# is convenient for making nice tables. Other packages can
# do much fancier things with tables, but keep in mind that
# the insights should be the star, not the formatting.
```

The next insight that we found is shown in \@ref(fig:insight2).

```{r insight2, fig.height=4, fig.width=6, fig.cap="This is a figure caption that you will need to change in order to get good marks in the visualization rubric items."}
# This figure will have a height of 4 and a width of 6.
# Feel free to change this, and to apply different sizes
# to the other figures you create.
```

Finally, \@ref(fig:insight3) shows ...

```{r insight3, fig.height=4, fig.width=6, fig.cap="This is a figure caption that you will need to change in order to get good marks in the visualization rubric items."}
```

# Conclusion and Future Work

Overall, we found <<general ideas>>.

A second paragraph about our findings.

The next steps in this analysis are...

The limitations of this analysis are as follows. (Do not simply list potential issues with sampling, but relate them to your analysis and how they affect your conclusions. An honest and complete acknowledgement of the limitations makes the analysis more trustworthy.)

# References

I am not strict about MLA or APA style or anything like that. For this report, I would much rather have your citations be easy to match to your insights.

The easiest way is to use Rmd's [footnote](https://bookdown.org/yihui/rmarkdown/markdown-syntax.html#inline-formatting) syntax. This will put a number beside the word where the footnote appears, and the full text of the footnote at the bottom of the page (pdf) or end of the document (html). The syntax is:^[See the source view to see this footnote], where I suggest that you put in something like this^[The relevance to the insight is ... . From <<name of source and name of article>>, published on <<date>>, url: <<link to page>>] to make references for this assignment.

Alternatively, you could make a list of citations with their main arguments and why they're relevent to your insights, methods, etc.

The link above also references "bibtex" files. These are also extremely convenient, but have a steep learning curve and they make it difficult to tie them to an insight. If you use bibtext, then make sure that you provide a sentence to describe the source and it's relevance when you cite it - don't just add citations to the end of a sentence (this is common practice in academia, but I want to know that your citations are directly relevant for this assignmnet).
